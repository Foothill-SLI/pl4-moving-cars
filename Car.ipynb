{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Car.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Qw5_ydfgLpIo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"26d4b6e4-df03-4803-d9f5-a78d70660192","executionInfo":{"status":"ok","timestamp":1572397942586,"user_tz":420,"elapsed":274,"user":{"displayName":"Raiymbek Akshulakov","photoUrl":"","userId":"15329972493861723321"}}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","# This will prompt for authorization.\n","drive.mount(\"/content/drive\")# Load the Drive helper and mount\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pkLVqVE5L0qj","colab_type":"code","colab":{}},"source":["directory = \"/content/drive/My Drive/SLI_2/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"THMElAtgMCv-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"843625a5-a5cf-49de-b0fe-0879d6e7b4b3","executionInfo":{"status":"error","timestamp":1572398186004,"user_tz":420,"elapsed":241805,"user":{"displayName":"Raiymbek Akshulakov","photoUrl":"","userId":"15329972493861723321"}}},"source":["import cv2\n","import numpy as np\n","import time\n","\n","trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n","\n","def createTrackerByName(trackerType):\n","  # Create a tracker based on tracker name\n","  if trackerType == trackerTypes[0]:\n","    tracker = cv2.TrackerBoosting_create()\n","  elif trackerType == trackerTypes[1]:\n","    tracker = cv2.TrackerMIL_create()\n","  elif trackerType == trackerTypes[2]:\n","    tracker = cv2.TrackerKCF_create()\n","  elif trackerType == trackerTypes[3]:\n","    tracker = cv2.TrackerTLD_create()\n","  elif trackerType == trackerTypes[4]:\n","    tracker = cv2.TrackerMedianFlow_create()\n","  elif trackerType == trackerTypes[5]:\n","    tracker = cv2.TrackerGOTURN_create()\n","  elif trackerType == trackerTypes[6]:\n","    tracker = cv2.TrackerMOSSE_create()\n","  elif trackerType == trackerTypes[7]:\n","    tracker = cv2.TrackerCSRT_create()\n","  else:\n","    tracker = None\n","    print('Incorrect tracker name')\n","    print('Available trackers are:')\n","    for t in trackerTypes:\n","      print(t)\n","\n","  return tracker\n","\n","\n","def preprocess(img, shave=False, shavedim=(350,500, 500,1000)):\n","    #if the image is to be cropped make sure the values are sane first then reduce the image down to the new dimentions\n","    if shave:\n","        if(shavedim[0] < 0):\n","            shavedim[0] = 0\n","        if (shavedim[1] > img.shape[0]):\n","            shavedim[1] = img.shape[0]\n","        if (shavedim[2] < 0):\n","            shavedim[2] = 0\n","        if (shavedim[3] > img.shape[1]):\n","            shavedim[3] = img.shape[1]\n","        img = img[shavedim[0]:shavedim[1],shavedim[2]:shavedim[3]]\n","    sizexy = [img.shape[1], img.shape[0]]\n","\n","    #get the appropriate padding on the image to make it square\n","    padhw = [0,0]\n","    if(sizexy[0] > sizexy[1]):\n","        dif = sizexy[0] - sizexy[1]\n","        border = cv2.copyMakeBorder(img, int(dif/2), int(dif/2), 0, 0, cv2.BORDER_CONSTANT, value=[200, 200, 200])\n","        padhw[0] = int(((dif/2)/border.shape[0]) * 448)\n","\n","    elif (sizexy[1] > sizexy[0]):\n","        dif = sizexy[1] - sizexy[0]\n","        border = cv2.copyMakeBorder(img, 0, 0, int(dif / 2), int(dif / 2), cv2.BORDER_CONSTANT, value=[200, 200, 200])\n","        padhw[1] = int(((dif / 2) / border.shape[1]) * 448)\n","    else:\n","        border = img\n","\n","    #resize the image to fit the 448,448 input that yolo requires\n","    border = cv2.resize(border, (448, 448))\n","\n","    #yolo requires the image to be fed in by (channel, y,x). Transpose to match that.\n","    transposed = np.transpose(border, [2, 0, 1])\n","    return transposed, padhw, shavedim, border\n","\n","\n","\n","CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n","    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n","    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n","    \"sofa\", \"train\", \"tvmonitor\"]\n","COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n","\n","net = cv2.dnn.readNetFromCaffe(directory + \"ssd/MobileNetSSD_deploy.prototxt.txt\", directory + \"ssd/MobileNetSSD_deploy.caffemodel\")\n","\n","vs = cv2.VideoCapture(directory + \"videos (1)/cars (1).mp4\")\n","multiTracker = cv2.MultiTracker_create()\n","writer = None\n","(w, h) = (None, None)\n","\n","try:\n","    prop = cv2.CAP_PROP_FRAME_COUNT\n","    total = int(vs.get(prop))\n","    print(\"[INFO] {} total frames in video\".format(total))\n","\n","# an error occurred while trying to determine the total\n","# number of frames in the video file\n","except:\n","    print(\"[INFO] could not determine # of frames in video\")\n","    print(\"[INFO] no approx. completion time can be provided\")\n","    total = -1\n","\n","multiTrackerList = []\n","\n","while True:\n","    # read the next frame from the file\n","    (grabbed, frame) = vs.read()\n","    #frame = cv2.resize(frame, (int(frame.shape[1]/2), int(frame.shape[0]/2)))\n","    # if the frame was not grabbed, then we have reached the end\n","    # of the stream\n","    if frame is None:\n","      print(\"kjh\")\n","      break\n","\n","    processed, padhw, shavedim, resized = preprocess(frame)\n","    frame = resized\n","\n","    # get updated location of objects in subsequent frames\n","    toDelete = []\n","    for oneTracker in multiTrackerList:\n","        (success, box) = oneTracker.update(frame)\n","\n","        # check to see if the tracking was a success\n","        if success:\n","            (x, y, W, H) = [int(v) for v in box]\n","            cv2.rectangle(frame, (x, y), (x + W, y + H),\n","                (0, 255, 0), 2)\n","    # if the frame dimensions are empty, grab them\n","    if w is None or h is None:\n","        (w, h) = frame.shape[:2]\n","\n","    blob = cv2.dnn.blobFromImage(frame, 0.007843, (448, 448), 127.5)\n","    net.setInput(blob)\n","    start = time.time()\n","    detections = net.forward()\n","    end = time.time()\n","\n","    # loop over each of the layer outputs\n","    for i in np.arange(0, detections.shape[2]):\n","    # extract the confidence (i.e., probability) associated with the\n","    # prediction\n","        confidence = detections[0, 0, i, 2]\n","\n","        # filter out weak detections by ensuring the `confidence` is\n","        # greater than the minimum confidence\n","        if confidence > 0.2:\n","            # extract the index of the class label from the `detections`,\n","            # then compute the (x, y)-coordinates of the bounding box for\n","            # the object\n","            idx = int(detections[0, 0, i, 1])\n","            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","            (startX, startY, endX, endY) = box.astype(\"int\")\n","\n","            # display the prediction\n","            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n","            if CLASSES[idx] == \"car\":\n","                tracker = cv2.TrackerCSRT_create()\n","                tracker.init(frame, (startX, startY, endX - startX, endY - startY))\n","                multiTrackerList.append(tracker)\n","                cv2.rectangle(frame, (startX, startY), (endX, endY), COLORS[idx], 2)\n","                y = startY - 15 if startY - 15 > 15 else startY + 15\n","                cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n","\n","\n","\n","\n","    if writer is None:\n","        # initialize our video writer\n","        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","        writer = cv2.VideoWriter(directory + \"output (1)/cars-ssd.avi\", fourcc, 30, (frame.shape[1], frame.shape[0]), True)\n","\n","        # some information on processing single frame\n","        if total > 0:\n","            elap = (end - start)\n","            print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n","            print(\"[INFO] estimated total time to finish: {:.4f}\".format(\n","                elap * total))\n","    # write the output frame to disk\n","    writer.write(frame)\n","\n","writer.release()\n","vs.release()\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[INFO] 15212 total frames in video\n","[INFO] single frame took 0.2725 seconds\n","[INFO] estimated total time to finish: 4145.1110\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-0566b8bc3726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Ha-D8Gx1MoBd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}